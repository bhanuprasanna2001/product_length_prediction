{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61852b40",
   "metadata": {},
   "source": [
    "# Amazon Product Length Prediction\n",
    "\n",
    "**Approach**: Multi-embedding ensemble with KNN retrieval features  \n",
    "**Architecture**: Pre-computed embeddings â†’ MLP regressor  \n",
    "**Metric**: MAPE (Mean Absolute Percentage Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b6b610",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c2721b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:04.176443Z",
     "iopub.status.busy": "2026-01-25T00:40:04.176178Z",
     "iopub.status.idle": "2026-01-25T00:40:11.100592Z",
     "shell.execute_reply": "2026-01-25T00:40:11.099739Z",
     "shell.execute_reply.started": "2026-01-25T00:40:04.176422Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.8.0+cu126\n",
      "Lightning: 2.6.0\n",
      "CUDA available: True\n",
      "GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# Weights & Biases for experiment tracking\n",
    "import wandb\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "pl.seed_everything(SEED)\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Lightning: {pl.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555b78ff-61c7-44d7-86e1-ef808d075ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:14.257859Z",
     "iopub.status.busy": "2026-01-25T00:40:14.257123Z",
     "iopub.status.idle": "2026-01-25T00:40:22.148614Z",
     "shell.execute_reply": "2026-01-25T00:40:22.147800Z",
     "shell.execute_reply.started": "2026-01-25T00:40:14.257825Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhanu-prasanna2001\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "try:\n",
    "    wandb.login(key=secret_value_0)\n",
    "except Exception as e:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22f9dd3",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e81fed",
   "metadata": {},
   "source": [
    "## 2.1 Quick Experiments (Change Config Here)\n",
    "\n",
    "**Recommended experiment order:**\n",
    "1. `loss_fn=\"mape\"` - Baseline (what you have: ~52%)\n",
    "2. `loss_fn=\"rmsle\"` - Better gradient flow, penalizes under-prediction\n",
    "3. `loss_fn=\"log_mape\"` - Handles wide value range\n",
    "4. `loss_fn=\"focal_mape\", focal_gamma=2.0` - Focus on hard examples\n",
    "5. `loss_fn=\"combined\"` - Balance MAPE + RMSLE\n",
    "6. `use_log_target=True` with any loss - Compress target range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab58776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:38.405990Z",
     "iopub.status.busy": "2026-01-25T00:40:38.405318Z",
     "iopub.status.idle": "2026-01-25T00:40:38.421386Z",
     "shell.execute_reply": "2026-01-25T00:40:38.420422Z",
     "shell.execute_reply.started": "2026-01-25T00:40:38.405944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embedding dim: 2048\n",
      "KNN dim: 20\n",
      "Active embeddings: ['minilm', 'mpnet', 'distiluse', 'e5small']\n",
      "Loss function: mape\n",
      "Log-target: True\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Training configuration.\"\"\"\n",
    "    # Paths (adjust for Kaggle)\n",
    "    data_dir: Path = Path(\"/kaggle/input/amazon-ml-challenge-2023/total_sentence_data/total_sentence_data\")\n",
    "    output_dir: Path = Path(\"/kaggle/working\")\n",
    "    embk20_dir: Path = Path(\"/kaggle/input/product-length-embeddings\")\n",
    "    \n",
    "    # Data splits\n",
    "    train_ratio: float = 0.85\n",
    "    val_ratio: float = 0.10\n",
    "    test_ratio: float = 0.05\n",
    "    \n",
    "    # Embeddings to use\n",
    "    active_embeddings: list = field(default_factory=lambda: [\"minilm\", \"mpnet\", \"distiluse\", \"e5small\"])\n",
    "    embedding_dims: dict = field(default_factory=lambda: {\n",
    "        \"minilm\": 384, \"mpnet\": 768, \"distiluse\": 512, \"e5small\": 384\n",
    "    })\n",
    "    \n",
    "    # KNN features\n",
    "    use_knn: bool = True\n",
    "    knn_k: int = 20\n",
    "    knn_embeddings: list = field(default_factory=lambda: [\"minilm\", \"mpnet\", \"distiluse\", \"e5small\"])\n",
    "    knn_ensemble: str = \"concat\"  # \"concat\" or \"mean\"\n",
    "    \n",
    "    # Model architecture\n",
    "    product_type_emb_dim: int = 128\n",
    "    hidden_dims: list = field(default_factory=lambda: [1024, 256, 64])\n",
    "    dropout: float = 0.2\n",
    "    use_batch_norm: bool = True\n",
    "    \n",
    "    # Training\n",
    "    batch_size: int = 512\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 0.01\n",
    "    epochs: int = 30\n",
    "    warmup_ratio: float = 0.05\n",
    "    patience: int = 5\n",
    "    gradient_clip_val: float = 1.0\n",
    "    num_workers: int = 2\n",
    "    \n",
    "    # Loss function: \"mape\", \"weighted_mape\", \"smape\", \"log_mape\", \"rmsle\", \"huber\", \"mse\", \"focal_mape\", \"combined\"\n",
    "    loss_fn: str = \"mape\"\n",
    "    huber_delta: float = 1.0\n",
    "    focal_gamma: float = 2.0  # For focal_mape\n",
    "    combined_alpha: float = 0.7  # For combined loss: alpha * MAPE + (1-alpha) * RMSLE\n",
    "    \n",
    "    # Log-transform target (helps with skewed distributions)\n",
    "    use_log_target: bool = True\n",
    "    \n",
    "    # W&B Logging\n",
    "    wandb_project: str = \"amazon-product-length\"\n",
    "    wandb_run_name: Optional[str] = None\n",
    "    log_every_n_steps: int = 50\n",
    "    val_check_interval: float = 0.25\n",
    "    \n",
    "    @property\n",
    "    def total_embedding_dim(self) -> int:\n",
    "        return sum(self.embedding_dims[e] for e in self.active_embeddings)\n",
    "    \n",
    "    @property\n",
    "    def knn_dim(self) -> int:\n",
    "        if not self.use_knn:\n",
    "            return 0\n",
    "        n_features = 5  # mean, std, median, min, max\n",
    "        if self.knn_ensemble == \"concat\":\n",
    "            return n_features * len(self.knn_embeddings)\n",
    "        return n_features\n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        \"\"\"Convert config to dict for W&B logging.\"\"\"\n",
    "        return {\n",
    "            \"data_dir\": str(self.data_dir),\n",
    "            \"output_dir\": str(self.output_dir),\n",
    "            \"train_ratio\": self.train_ratio,\n",
    "            \"val_ratio\": self.val_ratio,\n",
    "            \"test_ratio\": self.test_ratio,\n",
    "            \"active_embeddings\": self.active_embeddings,\n",
    "            \"total_embedding_dim\": self.total_embedding_dim,\n",
    "            \"use_knn\": self.use_knn,\n",
    "            \"knn_k\": self.knn_k,\n",
    "            \"knn_embeddings\": self.knn_embeddings,\n",
    "            \"knn_ensemble\": self.knn_ensemble,\n",
    "            \"knn_dim\": self.knn_dim,\n",
    "            \"product_type_emb_dim\": self.product_type_emb_dim,\n",
    "            \"hidden_dims\": self.hidden_dims,\n",
    "            \"dropout\": self.dropout,\n",
    "            \"use_batch_norm\": self.use_batch_norm,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"lr\": self.lr,\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"warmup_ratio\": self.warmup_ratio,\n",
    "            \"patience\": self.patience,\n",
    "            \"gradient_clip_val\": self.gradient_clip_val,\n",
    "            \"loss_fn\": self.loss_fn,\n",
    "            \"huber_delta\": self.huber_delta,\n",
    "            \"focal_gamma\": self.focal_gamma,\n",
    "            \"combined_alpha\": self.combined_alpha,\n",
    "            \"use_log_target\": self.use_log_target,\n",
    "        }\n",
    "\n",
    "\n",
    "cfg = Config()\n",
    "print(f\"Total embedding dim: {cfg.total_embedding_dim}\")\n",
    "print(f\"KNN dim: {cfg.knn_dim}\")\n",
    "print(f\"Active embeddings: {cfg.active_embeddings}\")\n",
    "print(f\"Loss function: {cfg.loss_fn}\")\n",
    "print(f\"Log-target: {cfg.use_log_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c33b6bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:40.893032Z",
     "iopub.status.busy": "2026-01-25T00:40:40.892201Z",
     "iopub.status.idle": "2026-01-25T00:40:40.898531Z",
     "shell.execute_reply": "2026-01-25T00:40:40.897845Z",
     "shell.execute_reply.started": "2026-01-25T00:40:40.892998Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ§ª EXPERIMENT: loss_fn=mape, log_target=True\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ðŸ”§ EXPERIMENT CONFIG - MODIFY THIS CELL TO TEST DIFFERENT SETTINGS\n",
    "# =============================================================================\n",
    "\n",
    "# Quick experiment toggles\n",
    "EXPERIMENT = {\n",
    "    \"loss_fn\": \"mape\",           # Try: \"mape\", \"rmsle\", \"log_mape\", \"focal_mape\", \"smape\", \"combined\"\n",
    "    \"use_log_target\": True,      # True compresses the target range (1-5000) â†’ (0-8.5)\n",
    "    \"focal_gamma\": 2.0,          # Only used if loss_fn=\"focal_mape\"\n",
    "    \"huber_delta\": 1.0,          # Only used if loss_fn=\"huber\"\n",
    "    \"combined_alpha\": 0.7,       # Only used if loss_fn=\"combined\" (alpha * MAPE + (1-alpha) * RMSLE)\n",
    "    \"wandb_run_name\": None,      # Set to custom name or None for auto-generated\n",
    "}\n",
    "\n",
    "# Override config with experiment settings\n",
    "cfg.loss_fn = EXPERIMENT[\"loss_fn\"]\n",
    "cfg.use_log_target = EXPERIMENT[\"use_log_target\"]\n",
    "cfg.focal_gamma = EXPERIMENT[\"focal_gamma\"]\n",
    "cfg.huber_delta = EXPERIMENT[\"huber_delta\"]\n",
    "cfg.combined_alpha = EXPERIMENT[\"combined_alpha\"]\n",
    "cfg.wandb_run_name = EXPERIMENT[\"wandb_run_name\"]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"ðŸ§ª EXPERIMENT: loss_fn={cfg.loss_fn}, log_target={cfg.use_log_target}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966d064f",
   "metadata": {},
   "source": [
    "## 2.2 W&B Logger Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa910f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:43.360964Z",
     "iopub.status.busy": "2026-01-25T00:40:43.360131Z",
     "iopub.status.idle": "2026-01-25T00:40:43.373956Z",
     "shell.execute_reply": "2026-01-25T00:40:43.373107Z",
     "shell.execute_reply.started": "2026-01-25T00:40:43.360925Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B logger and callbacks defined âœ“\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# W&B Logger and Custom Callbacks\n",
    "# =============================================================================\n",
    "\n",
    "def create_wandb_logger(config: Config) -> WandbLogger:\n",
    "    \"\"\"Create W&B logger for experiment tracking.\"\"\"\n",
    "    run_name = config.wandb_run_name or f\"ensemble_{config.loss_fn}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    return WandbLogger(\n",
    "        project=config.wandb_project,\n",
    "        name=run_name,\n",
    "        config=config.to_dict(),\n",
    "        save_dir=str(config.output_dir),\n",
    "    )\n",
    "\n",
    "\n",
    "class SamplePredictionCallback(pl.Callback):\n",
    "    \"\"\"Logs sample predictions to W&B for visual inspection.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_samples: int = 100):\n",
    "        self.num_samples = num_samples\n",
    "        \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if not trainer.val_dataloaders:\n",
    "            return\n",
    "            \n",
    "        preds, targets, types = [], [], []\n",
    "        pl_module.eval()\n",
    "        device = pl_module.device\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in trainer.val_dataloaders:\n",
    "                knn = batch.get(\"knn_features\")\n",
    "                pred = pl_module(\n",
    "                    batch[\"text_embedding\"].to(device),\n",
    "                    batch[\"product_type\"].to(device),\n",
    "                    knn_features=knn.to(device) if knn is not None else None,\n",
    "                )\n",
    "                preds.append(pred.cpu().numpy())\n",
    "                targets.append(batch[\"target\"].numpy())\n",
    "                types.append(batch[\"product_type\"].numpy())\n",
    "                \n",
    "                if sum(len(p) for p in preds) >= self.num_samples * 2:\n",
    "                    break\n",
    "        \n",
    "        preds, targets, types = np.concatenate(preds), np.concatenate(targets), np.concatenate(types)\n",
    "        idx = np.random.choice(len(preds), min(self.num_samples, len(preds)), replace=False)\n",
    "        \n",
    "        # Handle log-target transform if applicable\n",
    "        if pl_module.use_log_target:\n",
    "            targets = np.expm1(targets)\n",
    "            preds = np.expm1(preds)\n",
    "        \n",
    "        preds = np.maximum(preds, EPSILON)\n",
    "        \n",
    "        data = [\n",
    "            [targets[i], preds[i], abs(targets[i] - preds[i]), abs(targets[i] - preds[i]) / targets[i] * 100, int(types[i])]\n",
    "            for i in idx\n",
    "        ]\n",
    "        table = wandb.Table(columns=[\"true\", \"pred\", \"abs_error\", \"pct_error\", \"product_type\"], data=data)\n",
    "        wandb.log({\n",
    "            \"val_samples\": table,\n",
    "            \"epoch\": trainer.current_epoch,\n",
    "            \"pred_vs_true\": wandb.plot.scatter(table, \"true\", \"pred\", title=f\"Epoch {trainer.current_epoch}\")\n",
    "        })\n",
    "\n",
    "\n",
    "class MetricHistoryCallback(pl.Callback):\n",
    "    \"\"\"Tracks MAPE history across epochs.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_mape: list[float] = []\n",
    "        self.val_mape: list[float] = []\n",
    "        \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if \"train_mape\" in trainer.callback_metrics:\n",
    "            self.train_mape.append(trainer.callback_metrics[\"train_mape\"].item())\n",
    "            \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if \"val_mape\" in trainer.callback_metrics:\n",
    "            self.val_mape.append(trainer.callback_metrics[\"val_mape\"].item())\n",
    "\n",
    "\n",
    "print(\"W&B logger and callbacks defined âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15872ed8",
   "metadata": {},
   "source": [
    "## 3. Constants & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "358fac00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:45.985772Z",
     "iopub.status.busy": "2026-01-25T00:40:45.985148Z",
     "iopub.status.idle": "2026-01-25T00:40:46.002165Z",
     "shell.execute_reply": "2026-01-25T00:40:46.001457Z",
     "shell.execute_reply.started": "2026-01-25T00:40:45.985741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available losses: ['mape', 'weighted_mape', 'smape', 'log_mape', 'rmsle', 'huber', 'mse', 'focal_mape', 'combined']\n"
     ]
    }
   ],
   "source": [
    "EPSILON = 1e-6\n",
    "SCORE_SCALE = 100.0\n",
    "\n",
    "# =============================================================================\n",
    "# Loss Functions Registry\n",
    "# =============================================================================\n",
    "\n",
    "def mape_loss(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"MAPE loss - directly optimizes competition metric.\"\"\"\n",
    "    return torch.mean(torch.abs(target - pred) / target)\n",
    "\n",
    "\n",
    "def weighted_mape_loss(pred: torch.Tensor, target: torch.Tensor, scale: float = 100.0, min_weight: float = 0.1) -> torch.Tensor:\n",
    "    \"\"\"Weighted MAPE - downweights small targets to reduce their outsized influence.\"\"\"\n",
    "    weights = torch.clamp(target / scale, min=min_weight, max=1.0)\n",
    "    return torch.mean(weights * torch.abs(target - pred) / target)\n",
    "\n",
    "\n",
    "def smape_loss(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Symmetric MAPE - bounded [0, 2], handles zeros gracefully.\"\"\"\n",
    "    numerator = torch.abs(pred - target)\n",
    "    denominator = torch.abs(pred) + torch.abs(target) + EPSILON\n",
    "    return torch.mean(2.0 * numerator / denominator)\n",
    "\n",
    "\n",
    "def log_mape_loss(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Log-MAPE - better for wide value ranges (1 to 5000).\"\"\"\n",
    "    log_pred = torch.log(pred + EPSILON)\n",
    "    log_target = torch.log(target + EPSILON)\n",
    "    return torch.mean(torch.abs(log_pred - log_target) / (torch.abs(log_target) + EPSILON))\n",
    "\n",
    "\n",
    "def rmsle_loss(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"RMSLE - penalizes under-prediction more than over-prediction.\"\"\"\n",
    "    return torch.sqrt(torch.mean((torch.log1p(pred) - torch.log1p(target)) ** 2))\n",
    "\n",
    "\n",
    "def huber_loss(pred: torch.Tensor, target: torch.Tensor, delta: float = 1.0) -> torch.Tensor:\n",
    "    \"\"\"Huber loss in log-space - robust to outliers.\"\"\"\n",
    "    return F.huber_loss(torch.log1p(pred), torch.log1p(target), delta=delta)\n",
    "\n",
    "\n",
    "def mse_loss(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"MSE in log-space - simple baseline.\"\"\"\n",
    "    return F.mse_loss(torch.log1p(pred), torch.log1p(target))\n",
    "\n",
    "\n",
    "def focal_mape_loss(pred: torch.Tensor, target: torch.Tensor, gamma: float = 2.0) -> torch.Tensor:\n",
    "    \"\"\"Focal MAPE - focuses learning on hard examples with high error.\"\"\"\n",
    "    ape = torch.abs(target - pred) / target  # Absolute percentage error\n",
    "    focal_weight = (ape ** gamma)  # Hard examples get higher weight\n",
    "    focal_weight = focal_weight / (focal_weight.mean() + EPSILON)  # Normalize\n",
    "    return torch.mean(focal_weight * ape)\n",
    "\n",
    "\n",
    "def combined_loss(pred: torch.Tensor, target: torch.Tensor, alpha: float = 0.7) -> torch.Tensor:\n",
    "    \"\"\"Combined MAPE + RMSLE - balances percentage error with log-scale penalty.\"\"\"\n",
    "    return alpha * mape_loss(pred, target) + (1 - alpha) * rmsle_loss(pred, target)\n",
    "\n",
    "\n",
    "# Loss registry\n",
    "LOSS_REGISTRY = {\n",
    "    \"mape\": mape_loss,\n",
    "    \"weighted_mape\": weighted_mape_loss,\n",
    "    \"smape\": smape_loss,\n",
    "    \"log_mape\": log_mape_loss,\n",
    "    \"rmsle\": rmsle_loss,\n",
    "    \"huber\": huber_loss,\n",
    "    \"mse\": mse_loss,\n",
    "    \"focal_mape\": focal_mape_loss,\n",
    "    \"combined\": combined_loss,\n",
    "}\n",
    "\n",
    "\n",
    "def get_loss_fn(name: str, **kwargs):\n",
    "    \"\"\"Get loss function by name with optional kwargs.\"\"\"\n",
    "    if name not in LOSS_REGISTRY:\n",
    "        raise ValueError(f\"Unknown loss: {name}. Available: {list(LOSS_REGISTRY.keys())}\")\n",
    "    fn = LOSS_REGISTRY[name]\n",
    "    if kwargs:\n",
    "        return lambda p, t: fn(p, t, **kwargs)\n",
    "    return fn\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Metrics (PyTorch)\n",
    "# =============================================================================\n",
    "\n",
    "def compute_mape(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"MAPE as percentage for logging (0-100+).\"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred_safe = F.relu(pred) + EPSILON\n",
    "        return torch.mean(torch.abs(target - pred_safe) / target) * SCORE_SCALE\n",
    "\n",
    "\n",
    "def compute_rmsle(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Root Mean Squared Logarithmic Error.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred_safe = F.relu(pred) + EPSILON\n",
    "        return torch.sqrt(torch.mean((torch.log1p(pred_safe) - torch.log1p(target)) ** 2))\n",
    "\n",
    "\n",
    "def compute_score(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Competition score: max(0, 100 * (1 - MAPE/100)).\"\"\"\n",
    "    return torch.clamp(SCORE_SCALE - compute_mape(pred, target), min=0)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Metrics (NumPy)\n",
    "# =============================================================================\n",
    "\n",
    "def mape_numpy(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"MAPE as percentage (NumPy).\"\"\"\n",
    "    y_pred_safe = np.maximum(y_pred, EPSILON)\n",
    "    return float(np.mean(np.abs((y_true - y_pred_safe) / y_true)) * SCORE_SCALE)\n",
    "\n",
    "\n",
    "def rmsle_numpy(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"RMSLE (NumPy).\"\"\"\n",
    "    y_pred_safe = np.maximum(y_pred, EPSILON)\n",
    "    return float(np.sqrt(np.mean((np.log1p(y_pred_safe) - np.log1p(y_true)) ** 2)))\n",
    "\n",
    "\n",
    "def score_numpy(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Competition score (NumPy).\"\"\"\n",
    "    return max(0.0, SCORE_SCALE * (1 - mape_numpy(y_true, y_pred) / SCORE_SCALE))\n",
    "\n",
    "\n",
    "print(f\"Available losses: {list(LOSS_REGISTRY.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104fb3dc",
   "metadata": {},
   "source": [
    "## 4. Post-Processing (Snapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e9e8c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:48.629356Z",
     "iopub.status.busy": "2026-01-25T00:40:48.628680Z",
     "iopub.status.idle": "2026-01-25T00:40:48.639727Z",
     "shell.execute_reply": "2026-01-25T00:40:48.638854Z",
     "shell.execute_reply.started": "2026-01-25T00:40:48.629324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def snap_to_nearest(preds: np.ndarray, valid_lengths: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Snap predictions to nearest valid length using binary search.\"\"\"\n",
    "    if len(valid_lengths) == 0:\n",
    "        return preds\n",
    "    valid_sorted = np.sort(valid_lengths)\n",
    "    indices = np.searchsorted(valid_sorted, preds)\n",
    "    left_idx = np.maximum(indices - 1, 0)\n",
    "    right_idx = np.minimum(indices, len(valid_sorted) - 1)\n",
    "    left_vals, right_vals = valid_sorted[left_idx], valid_sorted[right_idx]\n",
    "    return np.where(np.abs(preds - left_vals) <= np.abs(preds - right_vals), left_vals, right_vals)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Snapper:\n",
    "    \"\"\"Snaps predictions to valid product lengths seen in training data.\"\"\"\n",
    "    all_valid_lengths: np.ndarray = None\n",
    "    lengths_by_type: dict = field(default_factory=dict)\n",
    "    min_length: float = 1.0\n",
    "    max_length: float = 5000.0\n",
    "    \n",
    "    def snap_by_type(self, preds: np.ndarray, product_types: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Snap using type-specific valid lengths.\"\"\"\n",
    "        if not self.lengths_by_type:\n",
    "            return snap_to_nearest(preds, self.all_valid_lengths)\n",
    "        result = preds.copy()\n",
    "        for ptype in np.unique(product_types):\n",
    "            mask = product_types == ptype\n",
    "            type_lengths = self.lengths_by_type.get(int(ptype), self.all_valid_lengths)\n",
    "            if type_lengths is not None and len(type_lengths) > 0:\n",
    "                result[mask] = snap_to_nearest(preds[mask], type_lengths)\n",
    "        return result\n",
    "    \n",
    "    def process(self, preds: np.ndarray, product_types: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Full post-processing: ensure positive â†’ snap â†’ clip.\"\"\"\n",
    "        result = np.maximum(preds, EPSILON)\n",
    "        result = self.snap_by_type(result, product_types)\n",
    "        return np.clip(result, self.min_length, self.max_length)\n",
    "\n",
    "\n",
    "def create_snapper(train_targets: np.ndarray, train_product_types: np.ndarray) -> Snapper:\n",
    "    \"\"\"Create Snapper from training data.\"\"\"\n",
    "    all_valid = np.sort(np.unique(train_targets))\n",
    "    lengths_by_type = {\n",
    "        int(pt): np.sort(np.unique(train_targets[train_product_types == pt]))\n",
    "        for pt in np.unique(train_product_types)\n",
    "    }\n",
    "    print(f\"Snapper: {len(all_valid):,} unique lengths, {len(lengths_by_type):,} product types\")\n",
    "    return Snapper(\n",
    "        all_valid_lengths=all_valid,\n",
    "        lengths_by_type=lengths_by_type,\n",
    "        min_length=float(train_targets.min()),\n",
    "        max_length=float(train_targets.max()),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af6229a",
   "metadata": {},
   "source": [
    "## 5. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa388636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:50.802647Z",
     "iopub.status.busy": "2026-01-25T00:40:50.802079Z",
     "iopub.status.idle": "2026-01-25T00:40:50.811136Z",
     "shell.execute_reply": "2026-01-25T00:40:50.810409Z",
     "shell.execute_reply.started": "2026-01-25T00:40:50.802614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    \"\"\"Dataset for pre-computed embeddings with optional KNN features.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings: dict[str, np.ndarray],\n",
    "        indices: np.ndarray,\n",
    "        product_types: np.ndarray,\n",
    "        targets: Optional[np.ndarray] = None,\n",
    "        product_ids: Optional[np.ndarray] = None,\n",
    "        knn_features: Optional[dict[str, np.ndarray]] = None,\n",
    "        knn_ensemble: str = \"concat\",\n",
    "        use_log_target: bool = False,\n",
    "    ):\n",
    "        self.embeddings = embeddings\n",
    "        self.indices = indices\n",
    "        self.product_types = product_types\n",
    "        self.targets = targets\n",
    "        self.product_ids = product_ids\n",
    "        self.knn_features = knn_features\n",
    "        self.knn_ensemble = knn_ensemble\n",
    "        self.use_log_target = use_log_target\n",
    "        self.model_names = list(embeddings.keys())\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        real_idx = self.indices[idx]\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        emb_list = [self.embeddings[name][real_idx] for name in self.model_names]\n",
    "        text_embedding = np.concatenate(emb_list, axis=0)\n",
    "        \n",
    "        item = {\n",
    "            \"text_embedding\": torch.tensor(text_embedding, dtype=torch.float32),\n",
    "            \"product_type\": torch.tensor(self.product_types[idx], dtype=torch.long),\n",
    "        }\n",
    "        \n",
    "        if self.targets is not None:\n",
    "            target = self.targets[idx]\n",
    "            if self.use_log_target:\n",
    "                target = np.log1p(target)  # log(1 + x) transform\n",
    "            item[\"target\"] = torch.tensor(target, dtype=torch.float32)\n",
    "            \n",
    "        if self.product_ids is not None:\n",
    "            item[\"product_id\"] = self.product_ids[idx]\n",
    "        \n",
    "        if self.knn_features is not None:\n",
    "            knn_list = [self.knn_features[name][real_idx] for name in sorted(self.knn_features.keys())]\n",
    "            if self.knn_ensemble == \"mean\":\n",
    "                combined = np.mean(knn_list, axis=0)\n",
    "            else:\n",
    "                combined = np.concatenate(knn_list, axis=0)\n",
    "            item[\"knn_features\"] = torch.tensor(combined, dtype=torch.float32)\n",
    "            \n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24998a40",
   "metadata": {},
   "source": [
    "## 6. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f81110a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:52.658871Z",
     "iopub.status.busy": "2026-01-25T00:40:52.658516Z",
     "iopub.status.idle": "2026-01-25T00:40:52.678879Z",
     "shell.execute_reply": "2026-01-25T00:40:52.677864Z",
     "shell.execute_reply.started": "2026-01-25T00:40:52.658839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MLPHead(nn.Module):\n",
    "    \"\"\"MLP regressor with batch normalization and dropout.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dims: list, dropout: float = 0.2, use_batch_norm: bool = True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        dim = input_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(dim, h))\n",
    "            if use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(h))\n",
    "            layers.extend([nn.ReLU(), nn.Dropout(dropout)])\n",
    "            dim = h\n",
    "        layers.append(nn.Linear(dim, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "\n",
    "class EnsembleModel(pl.LightningModule):\n",
    "    \"\"\"Embedding ensemble â†’ MLP regressor for product length prediction.\n",
    "    \n",
    "    Combines pre-computed text embeddings with product type embeddings and\n",
    "    optional KNN features, then feeds through MLP to predict length.\n",
    "    Supports log-target transform for handling skewed distributions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config, num_product_types: int):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"config\"])\n",
    "        self.config = config\n",
    "        self.use_log_target = config.use_log_target\n",
    "        \n",
    "        # Product type embedding (index 0 reserved for unknown)\n",
    "        self.product_emb = nn.Embedding(num_product_types, config.product_type_emb_dim, padding_idx=0)\n",
    "        nn.init.normal_(self.product_emb.weight, mean=0, std=0.02)\n",
    "        \n",
    "        # Input dimension calculation\n",
    "        input_dim = config.total_embedding_dim + config.product_type_emb_dim\n",
    "        \n",
    "        # Optional KNN feature projection (32-dim learned projection)\n",
    "        if config.knn_dim > 0:\n",
    "            self.knn_proj = nn.Sequential(nn.Linear(config.knn_dim, 32), nn.ReLU(), nn.Linear(32, 32))\n",
    "            input_dim += 32\n",
    "        else:\n",
    "            self.knn_proj = None\n",
    "        \n",
    "        self.head = MLPHead(input_dim, config.hidden_dims, config.dropout, config.use_batch_norm)\n",
    "        \n",
    "        # Configure loss function with appropriate kwargs\n",
    "        loss_kwargs = {}\n",
    "        if config.loss_fn == \"huber\":\n",
    "            loss_kwargs[\"delta\"] = config.huber_delta\n",
    "        elif config.loss_fn == \"focal_mape\":\n",
    "            loss_kwargs[\"gamma\"] = config.focal_gamma\n",
    "        elif config.loss_fn == \"combined\":\n",
    "            loss_kwargs[\"alpha\"] = config.combined_alpha\n",
    "        self.loss_fn = get_loss_fn(config.loss_fn, **loss_kwargs)\n",
    "        \n",
    "    def forward(self, text_embedding: torch.Tensor, product_type: torch.Tensor, knn_features: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        type_emb = self.product_emb(product_type)\n",
    "        \n",
    "        if knn_features is not None and self.knn_proj is not None:\n",
    "            parts = [text_embedding, type_emb, self.knn_proj(knn_features)]\n",
    "        else:\n",
    "            parts = [text_embedding, type_emb]\n",
    "            \n",
    "        return self.head(torch.cat(parts, dim=-1))\n",
    "    \n",
    "    def _compute_metrics(self, pred: torch.Tensor, target: torch.Tensor) -> dict[str, torch.Tensor]:\n",
    "        \"\"\"Compute all metrics for logging.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            pred_safe = F.relu(pred) + EPSILON\n",
    "            return {\n",
    "                \"mape\": compute_mape(pred_safe, target),\n",
    "                \"rmsle\": compute_rmsle(pred_safe, target),\n",
    "                \"score\": compute_score(pred_safe, target),\n",
    "            }\n",
    "    \n",
    "    def _step(self, batch: dict, stage: str) -> torch.Tensor:\n",
    "        pred = self(batch[\"text_embedding\"], batch[\"product_type\"], batch.get(\"knn_features\"))\n",
    "        pred_safe = F.relu(pred) + EPSILON\n",
    "        \n",
    "        target = batch[\"target\"]\n",
    "        if self.use_log_target:\n",
    "            # Transform back for loss/metrics computation\n",
    "            target_linear = torch.expm1(target)\n",
    "            pred_linear = torch.expm1(pred_safe)\n",
    "            loss = self.loss_fn(pred_linear, target_linear)\n",
    "            metrics = self._compute_metrics(pred_linear, target_linear)\n",
    "        else:\n",
    "            loss = self.loss_fn(pred_safe, target)\n",
    "            metrics = self._compute_metrics(pred_safe, target)\n",
    "        \n",
    "        # Log all metrics\n",
    "        self.log(f\"{stage}_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(f\"{stage}_mape\", metrics[\"mape\"], prog_bar=True, on_epoch=True)\n",
    "        self.log(f\"{stage}_rmsle\", metrics[\"rmsle\"], on_epoch=True)\n",
    "        self.log(f\"{stage}_score\", metrics[\"score\"], on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch: dict, batch_idx: int) -> torch.Tensor:\n",
    "        return self._step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch: dict, batch_idx: int) -> torch.Tensor:\n",
    "        return self._step(batch, \"val\")\n",
    "    \n",
    "    def test_step(self, batch: dict, batch_idx: int) -> torch.Tensor:\n",
    "        return self._step(batch, \"test\")\n",
    "    \n",
    "    def predict_step(self, batch: dict, batch_idx: int) -> torch.Tensor:\n",
    "        pred = self(batch[\"text_embedding\"], batch[\"product_type\"], batch.get(\"knn_features\"))\n",
    "        pred_safe = F.relu(pred) + EPSILON\n",
    "        if self.use_log_target:\n",
    "            pred_safe = torch.expm1(pred_safe)\n",
    "        return pred_safe\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config.lr, weight_decay=self.config.weight_decay)\n",
    "        total_steps = int(self.trainer.estimated_stepping_batches)\n",
    "        warmup_steps = int(self.config.warmup_ratio * total_steps)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer, max_lr=self.config.lr, total_steps=total_steps,\n",
    "            pct_start=warmup_steps / total_steps, anneal_strategy=\"cos\"\n",
    "        )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5db063",
   "metadata": {},
   "source": [
    "## 7. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d4906ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:56.001607Z",
     "iopub.status.busy": "2026-01-25T00:40:56.001212Z",
     "iopub.status.idle": "2026-01-25T00:40:56.009237Z",
     "shell.execute_reply": "2026-01-25T00:40:56.008591Z",
     "shell.execute_reply.started": "2026-01-25T00:40:56.001577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(cfg: Config):\n",
    "    \"\"\"Load embeddings, KNN features, and metadata.\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # Load train CSV for targets and product types\n",
    "    train_csv = cfg.data_dir / \"total_sentence_train.csv\"\n",
    "    test_csv = cfg.data_dir / \"total_sentence_test.csv\"\n",
    "    \n",
    "    train_df = pd.read_csv(train_csv)\n",
    "    test_df = pd.read_csv(test_csv)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_df):,}\")\n",
    "    print(f\"Test samples: {len(test_df):,}\")\n",
    "    \n",
    "    # Load embeddings (memory-mapped for efficiency)\n",
    "    embeddings = {}\n",
    "    for emb_name in cfg.active_embeddings:\n",
    "        path = cfg.embk20_dir / f\"{emb_name}_train.npy\"\n",
    "        embeddings[emb_name] = np.load(path, mmap_mode=\"r\")\n",
    "        print(f\"Loaded {emb_name}: {embeddings[emb_name].shape}\")\n",
    "    \n",
    "    # Load KNN features\n",
    "    knn_features = None\n",
    "    if cfg.use_knn:\n",
    "        knn_features = {}\n",
    "        for emb_name in cfg.knn_embeddings:\n",
    "            path = cfg.embk20_dir / f\"knn_k{cfg.knn_k}_{emb_name}_train.npy\"\n",
    "            knn_features[emb_name] = np.load(path, mmap_mode=\"r\")\n",
    "            print(f\"Loaded KNN ({emb_name}): {knn_features[emb_name].shape}\")\n",
    "    \n",
    "    # Build product type mapping\n",
    "    all_types = pd.concat([train_df[\"PRODUCT_TYPE_ID\"], test_df[\"PRODUCT_TYPE_ID\"]]).unique()\n",
    "    type_to_idx = {t: i + 1 for i, t in enumerate(sorted(all_types))}  # 0 reserved for unknown\n",
    "    num_product_types = len(type_to_idx) + 1\n",
    "    print(f\"Product types: {num_product_types:,}\")\n",
    "    \n",
    "    # Extract arrays\n",
    "    targets = train_df[\"PRODUCT_LENGTH\"].values.astype(np.float32)\n",
    "    product_types = train_df[\"PRODUCT_TYPE_ID\"].map(type_to_idx).values\n",
    "    \n",
    "    return {\n",
    "        \"embeddings\": embeddings,\n",
    "        \"knn_features\": knn_features,\n",
    "        \"targets\": targets,\n",
    "        \"product_types\": product_types,\n",
    "        \"num_product_types\": num_product_types,\n",
    "        \"type_to_idx\": type_to_idx,\n",
    "        \"train_df\": train_df,\n",
    "        \"test_df\": test_df,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "058933e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:57.238696Z",
     "iopub.status.busy": "2026-01-25T00:40:57.238021Z",
     "iopub.status.idle": "2026-01-25T00:40:57.243141Z",
     "shell.execute_reply": "2026-01-25T00:40:57.242545Z",
     "shell.execute_reply.started": "2026-01-25T00:40:57.238662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_splits(cfg: Config, data: dict):\n",
    "    \"\"\"Create train/val/test splits.\"\"\"\n",
    "    n = len(data[\"targets\"])\n",
    "    indices = np.random.permutation(n)\n",
    "    \n",
    "    train_end = int(cfg.train_ratio * n)\n",
    "    val_end = train_end + int(cfg.val_ratio * n)\n",
    "    \n",
    "    splits = {\n",
    "        \"train\": indices[:train_end],\n",
    "        \"val\": indices[train_end:val_end],\n",
    "        \"test\": indices[val_end:],\n",
    "    }\n",
    "    \n",
    "    print(f\"Splits: train={len(splits['train']):,}, val={len(splits['val']):,}, test={len(splits['test']):,}\")\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e312851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:40:58.405952Z",
     "iopub.status.busy": "2026-01-25T00:40:58.405426Z",
     "iopub.status.idle": "2026-01-25T00:40:58.412759Z",
     "shell.execute_reply": "2026-01-25T00:40:58.412180Z",
     "shell.execute_reply.started": "2026-01-25T00:40:58.405904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_dataloaders(cfg: Config, data: dict, splits: dict):\n",
    "    \"\"\"Create DataLoaders for each split.\"\"\"\n",
    "    \n",
    "    def make_dataset(split_indices: np.ndarray, include_targets: bool = True):\n",
    "        return EmbeddingDataset(\n",
    "            embeddings=data[\"embeddings\"],\n",
    "            indices=split_indices,\n",
    "            product_types=data[\"product_types\"][split_indices],\n",
    "            targets=data[\"targets\"][split_indices] if include_targets else None,\n",
    "            knn_features=data[\"knn_features\"],\n",
    "            knn_ensemble=cfg.knn_ensemble,\n",
    "            use_log_target=cfg.use_log_target,\n",
    "        )\n",
    "    \n",
    "    train_ds = make_dataset(splits[\"train\"])\n",
    "    val_ds = make_dataset(splits[\"val\"])\n",
    "    test_ds = make_dataset(splits[\"test\"])\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size * 2, shuffle=False, num_workers=cfg.num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=cfg.batch_size * 2, shuffle=False, num_workers=cfg.num_workers, pin_memory=True)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, {\"train\": train_ds, \"val\": val_ds, \"test\": test_ds}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc009d",
   "metadata": {},
   "source": [
    "## 8. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa553cc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:41:00.386343Z",
     "iopub.status.busy": "2026-01-25T00:41:00.385999Z",
     "iopub.status.idle": "2026-01-25T00:41:36.348337Z",
     "shell.execute_reply": "2026-01-25T00:41:36.347517Z",
     "shell.execute_reply.started": "2026-01-25T00:41:00.386312Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train samples: 2,173,199\n",
      "Test samples: 734,736\n",
      "Loaded minilm: (2173199, 384)\n",
      "Loaded mpnet: (2173199, 768)\n",
      "Loaded distiluse: (2173199, 512)\n",
      "Loaded e5small: (2173199, 384)\n",
      "Loaded KNN (minilm): (2173199, 5)\n",
      "Loaded KNN (mpnet): (2173199, 5)\n",
      "Loaded KNN (distiluse): (2173199, 5)\n",
      "Loaded KNN (e5small): (2173199, 5)\n",
      "Product types: 13,295\n",
      "Splits: train=1,847,219, val=217,319, test=108,661\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = load_data(cfg)\n",
    "splits = create_splits(cfg, data)\n",
    "train_loader, val_loader, test_loader, datasets = create_dataloaders(cfg, data, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f19e42ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:46:23.116098Z",
     "iopub.status.busy": "2026-01-25T00:46:23.115719Z",
     "iopub.status.idle": "2026-01-25T00:46:23.187333Z",
     "shell.execute_reply": "2026-01-25T00:46:23.186632Z",
     "shell.execute_reply.started": "2026-01-25T00:46:23.116066Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 4,247,105\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = EnsembleModel(cfg, data[\"num_product_types\"])\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88705df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:46:24.551422Z",
     "iopub.status.busy": "2026-01-25T00:46:24.550684Z",
     "iopub.status.idle": "2026-01-25T00:46:32.075780Z",
     "shell.execute_reply": "2026-01-25T00:46:32.075050Z",
     "shell.execute_reply.started": "2026-01-25T00:46:24.551389Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260125_004624-gqy952mk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhanu-prasanna2001/amazon-product-length/runs/gqy952mk' target=\"_blank\">ensemble_mape_20260125_004624</a></strong> to <a href='https://wandb.ai/bhanu-prasanna2001/amazon-product-length' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhanu-prasanna2001/amazon-product-length' target=\"_blank\">https://wandb.ai/bhanu-prasanna2001/amazon-product-length</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhanu-prasanna2001/amazon-product-length/runs/gqy952mk' target=\"_blank\">https://wandb.ai/bhanu-prasanna2001/amazon-product-length/runs/gqy952mk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B run: ensemble_mape_20260125_004624\n",
      "W&B project: amazon-product-length\n",
      "Trainer initialized with 7 callbacks\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Initialize W&B Logger\n",
    "# =============================================================================\n",
    "wandb_logger = create_wandb_logger(cfg)\n",
    "print(f\"W&B run: {wandb_logger.experiment.name}\")\n",
    "print(f\"W&B project: {cfg.wandb_project}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Callbacks\n",
    "# =============================================================================\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath=cfg.output_dir,\n",
    "        filename=\"ensemble-{epoch:02d}-{val_mape:.2f}\",\n",
    "        monitor=\"val_mape\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=3,\n",
    "    ),\n",
    "    EarlyStopping(monitor=\"val_mape\", patience=cfg.patience, mode=\"min\", verbose=True),\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "    SamplePredictionCallback(num_samples=100),\n",
    "    MetricHistoryCallback(),\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# Trainer with W&B\n",
    "# =============================================================================\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=cfg.epochs,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    precision=\"16-mixed\",\n",
    "    gradient_clip_val=cfg.gradient_clip_val,\n",
    "    callbacks=callbacks,\n",
    "    logger=wandb_logger,  # â† W&B experiment tracking\n",
    "    val_check_interval=cfg.val_check_interval,\n",
    "    log_every_n_steps=cfg.log_every_n_steps,\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "\n",
    "print(f\"Trainer initialized with {len(callbacks)} callbacks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b555dfeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T00:46:40.833386Z",
     "iopub.status.busy": "2026-01-25T00:46:40.832573Z",
     "iopub.status.idle": "2026-01-25T01:10:37.293106Z",
     "shell.execute_reply": "2026-01-25T01:10:37.292420Z",
     "shell.execute_reply.started": "2026-01-25T00:46:40.833348Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:881: Checkpoint directory /kaggle/working exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name        </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type       </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ product_emb â”‚ Embedding  â”‚  1.7 M â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ knn_proj    â”‚ Sequential â”‚  1.7 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>â”‚ head        â”‚ MLPHead    â”‚  2.5 M â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName       \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType      \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ product_emb â”‚ Embedding  â”‚  1.7 M â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ knn_proj    â”‚ Sequential â”‚  1.7 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0mâ”‚ head        â”‚ MLPHead    â”‚  2.5 M â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.2 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.2 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 16                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 20                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.2 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.2 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 16                                                                         \n",
       "\u001b[1mModules in train mode\u001b[0m: 20                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edad9cc122a148618d1f08ddba476c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mape improved. New best score: 95.180\n",
      "Metric val_mape improved by 21.710 >= min_delta = 0.0. New best score: 73.469\n",
      "Metric val_mape improved by 4.806 >= min_delta = 0.0. New best score: 68.663\n",
      "Metric val_mape improved by 4.462 >= min_delta = 0.0. New best score: 64.201\n",
      "Metric val_mape improved by 1.469 >= min_delta = 0.0. New best score: 62.732\n",
      "Metric val_mape improved by 4.377 >= min_delta = 0.0. New best score: 58.355\n",
      "Metric val_mape improved by 0.192 >= min_delta = 0.0. New best score: 58.163\n",
      "Metric val_mape improved by 1.245 >= min_delta = 0.0. New best score: 56.917\n",
      "Metric val_mape improved by 0.939 >= min_delta = 0.0. New best score: 55.978\n",
      "Metric val_mape improved by 0.793 >= min_delta = 0.0. New best score: 55.186\n",
      "Metric val_mape improved by 1.035 >= min_delta = 0.0. New best score: 54.151\n",
      "Metric val_mape improved by 0.090 >= min_delta = 0.0. New best score: 54.060\n",
      "Metric val_mape improved by 0.115 >= min_delta = 0.0. New best score: 53.945\n",
      "Metric val_mape improved by 1.131 >= min_delta = 0.0. New best score: 52.814\n",
      "Monitored metric val_mape did not improve in the last 5 records. Best score: 52.814. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220aaa1d",
   "metadata": {},
   "source": [
    "## 9. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bff66590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T01:11:13.825631Z",
     "iopub.status.busy": "2026-01-25T01:11:13.825287Z",
     "iopub.status.idle": "2026-01-25T01:11:13.987640Z",
     "shell.execute_reply": "2026-01-25T01:11:13.986989Z",
     "shell.execute_reply.started": "2026-01-25T01:11:13.825586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: /kaggle/working/ensemble-epoch=05-val_mape=52.81.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EnsembleModel(\n",
       "  (product_emb): Embedding(13295, 128, padding_idx=0)\n",
       "  (knn_proj): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (head): MLPHead(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=2208, out_features=1024, bias=True)\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): Dropout(p=0.2, inplace=False)\n",
       "      (8): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "      (11): Dropout(p=0.2, inplace=False)\n",
       "      (12): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best checkpoint\n",
    "best_ckpt = trainer.checkpoint_callback.best_model_path\n",
    "print(f\"Best checkpoint: {best_ckpt}\")\n",
    "\n",
    "model = EnsembleModel.load_from_checkpoint(best_ckpt, config=cfg, num_product_types=data[\"num_product_types\"])\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95c1a835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T01:11:20.438682Z",
     "iopub.status.busy": "2026-01-25T01:11:20.438361Z",
     "iopub.status.idle": "2026-01-25T01:11:20.446878Z",
     "shell.execute_reply": "2026-01-25T01:11:20.446269Z",
     "shell.execute_reply.started": "2026-01-25T01:11:20.438649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def collect_predictions(model, dataloader, device, use_log_target: bool = False):\n",
    "    \"\"\"Collect predictions from a dataloader.\"\"\"\n",
    "    model.eval()\n",
    "    preds, targets, ptypes = [], [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Predicting\"):\n",
    "        text_emb = batch[\"text_embedding\"].to(device)\n",
    "        product_type = batch[\"product_type\"].to(device)\n",
    "        knn = batch.get(\"knn_features\")\n",
    "        if knn is not None:\n",
    "            knn = knn.to(device)\n",
    "        \n",
    "        pred = model(text_emb, product_type, knn)\n",
    "        pred = F.relu(pred) + EPSILON\n",
    "        \n",
    "        # Transform back from log-space if needed\n",
    "        if use_log_target:\n",
    "            pred = torch.expm1(pred)\n",
    "        \n",
    "        preds.append(pred.cpu().numpy())\n",
    "        if \"target\" in batch:\n",
    "            target = batch[\"target\"]\n",
    "            if use_log_target:\n",
    "                target = torch.expm1(target)  # Transform back\n",
    "            targets.append(target.numpy())\n",
    "        ptypes.append(batch[\"product_type\"].numpy())\n",
    "    \n",
    "    result = {\n",
    "        \"preds\": np.concatenate(preds),\n",
    "        \"product_types\": np.concatenate(ptypes),\n",
    "    }\n",
    "    if targets:\n",
    "        result[\"targets\"] = np.concatenate(targets)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "574ebbf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T01:11:21.977179Z",
     "iopub.status.busy": "2026-01-25T01:11:21.976524Z",
     "iopub.status.idle": "2026-01-25T01:11:54.717158Z",
     "shell.execute_reply": "2026-01-25T01:11:54.716214Z",
     "shell.execute_reply.started": "2026-01-25T01:11:21.977150Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754309b0860d46889ef6073f0d18848c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapper: 10,802 unique lengths, 12,469 product types\n",
      "\n",
      "============================================================\n",
      "VALIDATION RESULTS (loss_fn=mape, log_target=True)\n",
      "============================================================\n",
      "  Raw MAPE: 52.82%\n",
      "  Raw RMSLE: 1.3694\n",
      "  Snapped MAPE: 53.16%\n",
      "  Snapped RMSLE: 1.3270\n",
      "  Improvement: -0.34%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "device = next(model.parameters()).device\n",
    "val_results = collect_predictions(model, val_loader, device, use_log_target=cfg.use_log_target)\n",
    "\n",
    "# Create snapper from training data\n",
    "snapper = create_snapper(\n",
    "    data[\"targets\"][splits[\"train\"]],\n",
    "    data[\"product_types\"][splits[\"train\"]],\n",
    ")\n",
    "\n",
    "# Evaluate validation set\n",
    "val_raw_mape = mape_numpy(val_results[\"targets\"], val_results[\"preds\"])\n",
    "val_raw_rmsle = rmsle_numpy(val_results[\"targets\"], val_results[\"preds\"])\n",
    "val_snapped_preds = snapper.process(val_results[\"preds\"], val_results[\"product_types\"])\n",
    "val_snapped_mape = mape_numpy(val_results[\"targets\"], val_snapped_preds)\n",
    "val_snapped_rmsle = rmsle_numpy(val_results[\"targets\"], val_snapped_preds)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"VALIDATION RESULTS (loss_fn={cfg.loss_fn}, log_target={cfg.use_log_target})\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Raw MAPE: {val_raw_mape:.2f}%\")\n",
    "print(f\"  Raw RMSLE: {val_raw_rmsle:.4f}\")\n",
    "print(f\"  Snapped MAPE: {val_snapped_mape:.2f}%\")\n",
    "print(f\"  Snapped RMSLE: {val_snapped_rmsle:.4f}\")\n",
    "print(f\"  Improvement: {val_raw_mape - val_snapped_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17889626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T01:12:15.213189Z",
     "iopub.status.busy": "2026-01-25T01:12:15.212345Z",
     "iopub.status.idle": "2026-01-25T01:12:23.433910Z",
     "shell.execute_reply": "2026-01-25T01:12:23.433155Z",
     "shell.execute_reply.started": "2026-01-25T01:12:15.213137Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4ed25ad7e94d10bb4d9c3e475983b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7bea28d97d80><function _MultiProcessingDataLoaderIter.__del__ at 0x7bea28d97d80>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "if w.is_alive():\n",
      "       Exception ignored in:    <function _MultiProcessingDataLoaderIter.__del__ at 0x7bea28d97d80>   \n",
      " ^^^Exception ignored in: Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7bea28d97d80>^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "\n",
      "^Traceback (most recent call last):\n",
      "^^^    ^^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "^    ^^self._shutdown_workers()self._shutdown_workers()\n",
      "^\n",
      "^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "^^        ^^\n",
      "if w.is_alive():\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "if w.is_alive():  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "         assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
      "   \n",
      "                   ^ ^   ^^  ^ ^^^  ^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^    ^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n",
      "\n",
      "^ ^^   ^  ^ ^  ^^^  ^  ^^ ^  ^ ^^   ^^^ ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^AssertionError^^^^\n",
      ": ^AssertionErrorcan only test a child process^: \n",
      "^^can only test a child process\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError^^^: ^can only test a child process^\n",
      "^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST RESULTS (loss_fn=mape, log_target=True)\n",
      "============================================================\n",
      "  Raw MAPE: 50.58%\n",
      "  Raw RMSLE: 1.3666\n",
      "  Snapped MAPE: 51.89%\n",
      "  Snapped RMSLE: 1.3248\n",
      "  Improvement: -1.31%\n",
      "\n",
      "ðŸ“Š Competition Score: 48.11\n",
      "\n",
      "âœ… Final metrics logged to W&B\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_results = collect_predictions(model, test_loader, device, use_log_target=cfg.use_log_target)\n",
    "\n",
    "test_raw_mape = mape_numpy(test_results[\"targets\"], test_results[\"preds\"])\n",
    "test_raw_rmsle = rmsle_numpy(test_results[\"targets\"], test_results[\"preds\"])\n",
    "test_snapped_preds = snapper.process(test_results[\"preds\"], test_results[\"product_types\"])\n",
    "test_snapped_mape = mape_numpy(test_results[\"targets\"], test_snapped_preds)\n",
    "test_snapped_rmsle = rmsle_numpy(test_results[\"targets\"], test_snapped_preds)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TEST RESULTS (loss_fn={cfg.loss_fn}, log_target={cfg.use_log_target})\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Raw MAPE: {test_raw_mape:.2f}%\")\n",
    "print(f\"  Raw RMSLE: {test_raw_rmsle:.4f}\")\n",
    "print(f\"  Snapped MAPE: {test_snapped_mape:.2f}%\")\n",
    "print(f\"  Snapped RMSLE: {test_snapped_rmsle:.4f}\")\n",
    "print(f\"  Improvement: {test_raw_mape - test_snapped_mape:.2f}%\")\n",
    "print(f\"\\nðŸ“Š Competition Score: {max(0, 100 * (1 - test_snapped_mape / 100)):.2f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Log Final Results to W&B\n",
    "# =============================================================================\n",
    "wandb.log({\n",
    "    # Validation metrics\n",
    "    \"final_val_mape_raw\": val_raw_mape,\n",
    "    \"final_val_mape_snapped\": val_snapped_mape,\n",
    "    \"final_val_rmsle_raw\": val_raw_rmsle,\n",
    "    \"final_val_rmsle_snapped\": val_snapped_rmsle,\n",
    "    # Test metrics\n",
    "    \"final_test_mape_raw\": test_raw_mape,\n",
    "    \"final_test_mape_snapped\": test_snapped_mape,\n",
    "    \"final_test_rmsle_raw\": test_raw_rmsle,\n",
    "    \"final_test_rmsle_snapped\": test_snapped_rmsle,\n",
    "    # Competition score\n",
    "    \"final_competition_score\": max(0, 100 * (1 - test_snapped_mape / 100)),\n",
    "    # Post-processing improvement\n",
    "    \"val_snapping_improvement\": val_raw_mape - val_snapped_mape,\n",
    "    \"test_snapping_improvement\": test_raw_mape - test_snapped_mape,\n",
    "})\n",
    "\n",
    "print(\"\\nâœ… Final metrics logged to W&B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19ef964a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T01:12:46.838581Z",
     "iopub.status.busy": "2026-01-25T01:12:46.837758Z",
     "iopub.status.idle": "2026-01-25T01:12:47.918512Z",
     "shell.execute_reply": "2026-01-25T01:12:47.917691Z",
     "shell.execute_reply.started": "2026-01-25T01:12:46.838527Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>final_competition_score</td><td>â–</td></tr><tr><td>final_test_mape_raw</td><td>â–</td></tr><tr><td>final_test_mape_snapped</td><td>â–</td></tr><tr><td>final_test_rmsle_raw</td><td>â–</td></tr><tr><td>final_test_rmsle_snapped</td><td>â–</td></tr><tr><td>final_val_mape_raw</td><td>â–</td></tr><tr><td>final_val_mape_snapped</td><td>â–</td></tr><tr><td>final_val_rmsle_raw</td><td>â–</td></tr><tr><td>final_val_rmsle_snapped</td><td>â–</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_checkpoint</td><td>/kaggle/working/ense...</td></tr><tr><td>best_test_mape</td><td>51.8915</td></tr><tr><td>best_val_mape</td><td>53.15826</td></tr><tr><td>competition_score</td><td>48.1085</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>final_competition_score</td><td>48.1085</td></tr><tr><td>final_test_mape_raw</td><td>50.57744</td></tr><tr><td>final_test_mape_snapped</td><td>51.8915</td></tr><tr><td>final_test_rmsle_raw</td><td>1.36663</td></tr><tr><td>final_test_rmsle_snapped</td><td>1.32479</td></tr><tr><td>+20</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ensemble_mape_20260125_004624</strong> at: <a href='https://wandb.ai/bhanu-prasanna2001/amazon-product-length/runs/gqy952mk' target=\"_blank\">https://wandb.ai/bhanu-prasanna2001/amazon-product-length/runs/gqy952mk</a><br> View project at: <a href='https://wandb.ai/bhanu-prasanna2001/amazon-product-length' target=\"_blank\">https://wandb.ai/bhanu-prasanna2001/amazon-product-length</a><br>Synced 5 W&B file(s), 29 media file(s), 58 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260125_004624-gqy952mk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… W&B run completed and synced!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Finish W&B Run\n",
    "# =============================================================================\n",
    "\n",
    "# Log summary metrics to W&B\n",
    "wandb.summary.update({\n",
    "    \"best_val_mape\": val_snapped_mape,\n",
    "    \"best_test_mape\": test_snapped_mape,\n",
    "    \"competition_score\": max(0, 100 * (1 - test_snapped_mape / 100)),\n",
    "    \"best_checkpoint\": best_ckpt,\n",
    "})\n",
    "\n",
    "# Finish the W&B run\n",
    "wandb.finish()\n",
    "print(\"âœ… W&B run completed and synced!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7c222a",
   "metadata": {},
   "source": [
    "## 10. Analysis (Optional)\n",
    "\n",
    "Run the next cell to analyze prediction errors by product type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "484159ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T01:12:57.731415Z",
     "iopub.status.busy": "2026-01-25T01:12:57.731096Z",
     "iopub.status.idle": "2026-01-25T01:12:58.867114Z",
     "shell.execute_reply": "2026-01-25T01:12:58.866425Z",
     "shell.execute_reply.started": "2026-01-25T01:12:57.731387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Top 20 Worst Product Types by MAPE:\n",
      " product_type  count        mape  mean_target  std_target\n",
      "        12843     16 4936.958984   782.178650  511.498199\n",
      "         7244     10 2425.075439   517.517334  335.068817\n",
      "          727     12 1180.388672   661.578125  355.773560\n",
      "        13170     45  890.932739   755.858826  599.768677\n",
      "         2521     21  622.372559  1200.628784  607.809082\n",
      "         2948     22  511.731659   706.349304  368.515106\n",
      "         2275    163  508.802612   942.381409  772.823853\n",
      "         3298    180  486.257324   901.300354  328.622162\n",
      "        11872     22  381.994141   482.800079  329.424988\n",
      "        13218     16  359.625732   590.777588  523.759338\n",
      "         5082     20  346.414124  1096.650024  512.888184\n",
      "         3432     10  300.478302   325.284973  234.886520\n",
      "         6501     16  280.408752   665.902588  360.324066\n",
      "         7789     10  236.194443   706.709290  334.541534\n",
      "          142     27  221.893982   696.344238  193.308929\n",
      "         1148     12  218.250229   648.784119  682.486206\n",
      "         3375     65  211.929993   869.480408  828.127197\n",
      "        11053     19  208.200256   875.859863  868.249268\n",
      "          217     11  195.533829   553.652832  251.747467\n",
      "           72     13  190.769440   648.687195  197.199249\n",
      "\n",
      "ðŸ“Š Top 20 Best Product Types by MAPE:\n",
      " product_type  count     mape  mean_target  std_target\n",
      "        11541     32 8.069408   553.206116  123.519341\n",
      "         7399     40 7.933360   443.253967  161.074310\n",
      "         6091     17 7.769965   640.705688   73.456467\n",
      "        12298    127 7.572313   641.950256   78.935997\n",
      "        11923     13 7.519852   648.160828   71.395103\n",
      "         5733     11 7.483345   397.279388   48.812408\n",
      "        12398     19 7.416283    86.614014    0.000000\n",
      "        12123     12 7.261563   600.063354   38.218227\n",
      "          746     34 7.096897   524.010498   33.964359\n",
      "         6317     13 6.739114   630.165894   74.865021\n",
      "          820     28 6.621676   566.535706  125.515396\n",
      "         6245     26 6.572224   642.087952   62.469246\n",
      "         1863     24 6.501766   164.871048  132.177673\n",
      "         6070     14 6.391957   647.538879   75.798569\n",
      "        12116     15 6.207271   589.061523   30.279833\n",
      "          750     22 5.448987   534.874268   30.517612\n",
      "        12662     11 5.378371   587.000000   40.145164\n",
      "         2213    133 5.202442   607.790405  234.273392\n",
      "         4089     13 3.296714  1246.154053   84.265068\n",
      "         7046     12 0.000008    99.999992    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Optional: Analyze errors by product type\n",
    "def analyze_errors_by_type(preds: np.ndarray, targets: np.ndarray, product_types: np.ndarray, top_k: int = 20):\n",
    "    \"\"\"Analyze MAPE by product type to identify problem areas.\"\"\"\n",
    "    unique_types = np.unique(product_types)\n",
    "    type_errors = []\n",
    "    \n",
    "    for ptype in unique_types:\n",
    "        mask = product_types == ptype\n",
    "        if mask.sum() < 10:  # Skip rare types\n",
    "            continue\n",
    "        type_mape = mape_numpy(targets[mask], preds[mask])\n",
    "        type_errors.append({\n",
    "            \"product_type\": int(ptype),\n",
    "            \"count\": int(mask.sum()),\n",
    "            \"mape\": type_mape,\n",
    "            \"mean_target\": float(targets[mask].mean()),\n",
    "            \"std_target\": float(targets[mask].std()),\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(type_errors).sort_values(\"mape\", ascending=False)\n",
    "    print(f\"\\nðŸ“Š Top {top_k} Worst Product Types by MAPE:\")\n",
    "    print(df.head(top_k).to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Top {top_k} Best Product Types by MAPE:\")\n",
    "    print(df.tail(top_k).to_string(index=False))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Uncomment to run analysis:\n",
    "error_analysis = analyze_errors_by_type(test_snapped_preds, test_results[\"targets\"], test_results[\"product_types\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b553041",
   "metadata": {},
   "source": [
    "## ðŸ“ Experiment Log\n",
    "\n",
    "Track your experiments here:\n",
    "\n",
    "| Experiment | Loss | Log Target | Val MAPE | Test MAPE | Notes |\n",
    "|------------|------|------------|----------|-----------|-------|\n",
    "| Baseline | mape | False | 51.78% | - | Current best |\n",
    "| Exp 2 | rmsle | False | - | - | |\n",
    "| Exp 3 | log_mape | False | - | - | |\n",
    "| Exp 4 | focal_mape | False | - | - | Î³=2.0 |\n",
    "| Exp 5 | mape | True | - | - | Log-transform target |\n",
    "| Exp 6 | combined | False | - | - | 0.7Â·MAPE + 0.3Â·RMSLE |\n",
    "\n",
    "### Next Steps After Loss Experiments\n",
    "1. **Ensemble**: Train top 3 losses, average predictions\n",
    "2. **Architecture**: Try larger KNN projection (32 â†’ 64)\n",
    "3. **Learning Rate**: Try lr=3e-4 or lr=5e-4\n",
    "4. **Deeper MLP**: [1024, 512, 256, 64] instead of [1024, 256, 64]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3159862,
     "sourceId": 5484054,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9330513,
     "sourceId": 14607287,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
